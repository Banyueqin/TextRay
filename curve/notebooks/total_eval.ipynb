{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_pred correct/all (1692/2210); num_gt correct/all (1692/2215)\n",
      "precision: 76.561086%\n",
      "recall: 76.388262%\n",
      "f-measure: 76.474576%\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon, LineString, MultiLineString, GeometryCollection\n",
    "from shapely.algorithms.polylabel import polylabel\n",
    "import math\n",
    "import cv2\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "def load_ann(filename):\n",
    "    with open(filename) as f:\n",
    "        texts = f.read().split('x: [[')[1:]\n",
    "    num_objs = len(texts)\n",
    "    polygon_list = []\n",
    "    for i in range(num_objs):\n",
    "        try:\n",
    "            text = texts[i].split(',')\n",
    "            x = text[0][:-2].split()\n",
    "            x = np.array(x, dtype = np.float32)\n",
    "            y = text[1][6:-2].split()\n",
    "            y = np.array(y, dtype = np.float32)\n",
    "            box = np.hstack((x[:, np.newaxis], y[:, np.newaxis]))\n",
    "            hard = (text[-1][20:-3] == '#')\n",
    "            polygon = Polygon(box)\n",
    "        except Exception as err:\n",
    "            print(filename, texts[i], err)\n",
    "        polygon_list.append([polygon, hard])\n",
    "    return polygon_list\n",
    "\n",
    "def load_pred(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        array = pickle.load(f)\n",
    "    pred_polygon_list = []\n",
    "    for pred_per_sample in array:\n",
    "        polygon_list = []\n",
    "        for pred_one_out in pred_per_sample:\n",
    "            coords = pred_one_out[:-1]\n",
    "            score = float(pred_one_out[-1])\n",
    "            if score < 0.995:\n",
    "                continue\n",
    "            polygon = Polygon(coords.reshape((-1, 2)))\n",
    "            polygon_list.append(polygon)\n",
    "        pred_polygon_list.append(polygon_list)\n",
    "    return pred_polygon_list\n",
    "\n",
    "def polygon_iou(poly1, poly2):\n",
    "    \"\"\"\n",
    "    Intersection over union between two shapely polygons.\n",
    "    \"\"\"\n",
    "    iou = 0.0\n",
    "    if poly1.intersects(poly2):\n",
    "        try:\n",
    "            inter_area = poly1.intersection(poly2).area\n",
    "            union_area = poly1.area + poly2.area - inter_area\n",
    "            iou = float(inter_area) / union_area\n",
    "        except Exception as err:\n",
    "            iou = 0.5\n",
    "#             print(poly1)\n",
    "    return iou\n",
    "\n",
    "def evaluation(pred_polygon_list, gt_polygon_list):\n",
    "    assert len(pred_polygon_list)==len(gt_polygon_list), \"sample numbers should be same\"\n",
    "    num_gt = 0\n",
    "    num_pred = 0\n",
    "    num_gt_correct = 0\n",
    "    num_pred_correct = 0\n",
    "    for sample_idx in range(len(pred_polygon_list)):\n",
    "        gt_polygons = gt_polygon_list[sample_idx]\n",
    "        pred_polygons = pred_polygon_list[sample_idx]\n",
    "        num_gt += len(gt_polygons)\n",
    "        num_pred += len(pred_polygons)\n",
    "        for gt_polygon, hard in gt_polygons:\n",
    "            num_gt -= 1 if hard else 0\n",
    "            gt_correct = False\n",
    "            for pred_polygon in pred_polygons:\n",
    "                iou = polygon_iou(gt_polygon, pred_polygon)\n",
    "                if iou >= 0.5:\n",
    "                    num_pred_correct += 1 if not hard else 0\n",
    "                    num_pred -= 1 if hard else 0\n",
    "                    gt_correct = True\n",
    "            num_gt_correct += 1 if (gt_correct and not hard) else 0\n",
    "    p = 1.0 * num_pred_correct / max(num_pred, 1e-10)\n",
    "    r = 1.0 * num_gt_correct / max(num_gt, 1e-10)\n",
    "    f = 2.0 * p * r / max(p + r, 1e-10)\n",
    "    print(\"num_pred correct/all (%d/%d); num_gt correct/all (%d/%d)\"%(num_pred_correct, num_pred, num_gt_correct, num_gt))\n",
    "    print(\"precision: %f%%\"%(p*100.0))\n",
    "    print(\"recall: %f%%\"%(r*100.0))\n",
    "    print(\"f-measure: %f%%\"%(f*100.0))\n",
    "        \n",
    "# load pred pickle\n",
    "pickle_file = '../../experiments/total_33d/total_33d_05022133.pkl' #wff_total_04031144'/home/wff/curve-text/' + 'total_with_pretrain.pkl'\n",
    "pred_polygon_list = load_pred(pickle_file)\n",
    "# load gt ann\n",
    "img_prefix = '/home/wff/curve-text/data/TotalText/'\n",
    "test_file = os.path.join(img_prefix, 'ImageSets/Main/test.txt')\n",
    "img_ids = mmcv.list_from_file(test_file)\n",
    "gt_polygon_list = []\n",
    "for img_id in img_ids:\n",
    "    ann_file = os.path.join(img_prefix, 'Annotations', img_id + '.txt')\n",
    "    gt_polygon_list.append(load_ann(ann_file))\n",
    "# evaluation\n",
    "result = evaluation(pred_polygon_list, gt_polygon_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total done 300\n",
      "art done 5591\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon, LineString, MultiLineString, GeometryCollection\n",
    "from shapely.algorithms.polylabel import polylabel\n",
    "import math\n",
    "import cv2\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# load gt ann\n",
    "import hashlib\n",
    "total_prefix = '/home/wff/curve-text/data/TotalText/'\n",
    "test_file = os.path.join(total_prefix, 'ImageSets/Main/test.txt')\n",
    "total_ids = mmcv.list_from_file(test_file)\n",
    "total = dict()\n",
    "for i in total_ids:\n",
    "    total_jpg = os.path.join(total_prefix, 'JPGImages', i + '.jpg')\n",
    "    file_md5 = hashlib.md5(open(total_jpg, 'rb').read()).hexdigest()\n",
    "    total[file_md5] = total_jpg\n",
    "print('total done', len(total))\n",
    "\n",
    "art_prefix = '/home/wff/curve-text/data/ArT/'\n",
    "train_file = os.path.join(art_prefix, 'ImageSets/Main/train.txt')\n",
    "art_ids = mmcv.list_from_file(train_file)\n",
    "art = dict()\n",
    "for j in art_ids:\n",
    "    art_jpg = os.path.join(art_prefix, 'JPGImages', j + '.jpg')\n",
    "    file_md5 = hashlib.md5(open(art_jpg, 'rb').read()).hexdigest()\n",
    "    art[file_md5] = art_jpg\n",
    "print('art done', len(art))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare test done\n"
     ]
    }
   ],
   "source": [
    "for key in total:\n",
    "    if key in art:\n",
    "        print(total[key], art[key])\n",
    "print(\"compare test done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total done 1255\n",
      "compare train done\n"
     ]
    }
   ],
   "source": [
    "total_prefix = '/home/wff/curve-text/data/TotalText/'\n",
    "train_file = os.path.join(total_prefix, 'ImageSets/Main/train.txt')\n",
    "total_ids = mmcv.list_from_file(train_file)\n",
    "total = dict()\n",
    "for i in total_ids:\n",
    "    total_jpg = os.path.join(total_prefix, 'JPGImages', i + '.jpg')\n",
    "    file_md5 = hashlib.md5(open(total_jpg, 'rb').read()).hexdigest()\n",
    "    total[file_md5] = total_jpg\n",
    "print('total done', len(total))\n",
    "for key in total:\n",
    "    if key in art:\n",
    "        print(total[key], art[key])\n",
    "print(\"compare train done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_prefix = '/home/wff/curve-text/data/CTW1500/'\n",
    "train_file = os.path.join(total_prefix, 'ImageSets/Main/train.txt')\n",
    "total_ids = mmcv.list_from_file(train_file)\n",
    "total = dict()\n",
    "for i in total_ids:\n",
    "    total_jpg = os.path.join(total_prefix, 'JPGImages', i + '.jpg')\n",
    "    file_md5 = hashlib.md5(open(total_jpg, 'rb').read()).hexdigest()\n",
    "    total[file_md5] = total_jpg\n",
    "print('CTW1500 done', len(total))\n",
    "for key in total:\n",
    "    if key in art:\n",
    "        print(total[key], art[key])\n",
    "print(\"compare train done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(total)):\n",
    "    for j in range(len(art)):\n",
    "        if total[i].shape == art[j].shape:\n",
    "            if (total[i] == art[j]).all():\n",
    "                print('same picture:',total_ids[i], art_ids[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train done\n"
     ]
    }
   ],
   "source": [
    "total_prefix = '/home/wff/curve-text/data/TotalText/'\n",
    "total_train_file = os.path.join(total_prefix, 'ImageSets/Main/train.txt')\n",
    "total_train_ids = mmcv.list_from_file(total_train_file)\n",
    "total_train = []\n",
    "for i in total_train_ids:\n",
    "    total_jpg = os.path.join(total_prefix, 'JPGImages', i + '.jpg')\n",
    "    total_train.append(cv2.imread(total_jpg))\n",
    "print('total train done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(total_train)):\n",
    "    for j in range(len(art)):\n",
    "        if total_train[i].shape == art[j].shape:\n",
    "            if (total_train[i] == art[j]).all():\n",
    "                print('same picture:',total_train_ids[i], art_ids[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_prefix = '/home/wff/curve-text/data/ArT/'\n",
    "art_test_file = os.path.join(art_prefix, 'ImageSets/Main/test.txt')\n",
    "art_test_ids = mmcv.list_from_file(art_test_file)\n",
    "art_test = []\n",
    "for j in art_test_ids:\n",
    "    art_jpg = os.path.join(art_prefix, 'JPGImages', j + '.jpg')\n",
    "    art_test.append(cv2.imread(art_jpg))\n",
    "print('art test done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
